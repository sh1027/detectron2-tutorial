{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "detectron2_tutorial.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sh1027/detectron2_tutorial/blob/main/detectron2_tutorial.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Detectron2 チュートリアル\n",
        "<img src=\"https://dl.fbaipublicfiles.com/detectron2/Detectron2-Logo-Horz.png\" width=\"500\">\n",
        "\n",
        "本チュートリアルでは，Detectron2の事前学習済みモデルを用いて，物体検出やその関連タスクの推論を試します．\n",
        "\n",
        "✅ 推論を試すタスク\n",
        "\n",
        "*   物体検出 (Object Detection)\n",
        "*   Instance Segmentation\n",
        "*   Keypoint Detection\n",
        "*   Panoptic Segmentation\n",
        "\n",
        "✅ 推論を試す入力\n",
        "\n",
        "*   COCO Datasetの画像\n",
        "*   Google Drive内の画像\n",
        "*   Google Drive内の動画\n",
        "*   Youtubeの動画"
      ],
      "metadata": {
        "id": "dxFXHcEEb6Ur"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 目次\n",
        "\n",
        "1.   セットアップ\n",
        "2.   COCOデータセットの画像を用いた推論（物体検出）\n",
        "3.   COCOデータセットの画像を用いた推論（関連タスク）\n",
        "4.   Google Drive内の画像を用いた推論\n",
        "5.   動画を用いた推論\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "xtl2MZ1vKKd6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. セットアップ"
      ],
      "metadata": {
        "id": "ZqoPWO-op3r1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "pytorchと，pytorchのバージョンに合ったdetectron2をインストールします．\n",
        "\n",
        "実行後にランタイムを再起動してください．"
      ],
      "metadata": {
        "id": "GYhJKGwNm0Pj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch==1.10.0+cu111 torchvision==0.11.0+cu111 -f https://download.pytorch.org/whl/torch_stable.html\n",
        "!pip install detectron2 -f \\https://dl.fbaipublicfiles.com/detectron2/wheels/cu111/torch1.10/index.html"
      ],
      "metadata": {
        "id": "wWDLxGK1gpvZ",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "ランタイムの再起動後に，pytorchのバージョンをチェックします．以下のように出力されればOKです．\n",
        "\n",
        "```\n",
        "torch version           : 1.10.0+cu111\n",
        "torch cuda is available : True\n",
        "detectron2 version      : 0.6\n",
        "```"
      ],
      "metadata": {
        "id": "XS2mRmSsn4TQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import detectron2\n",
        "print(\"torch version           :\", torch.__version__)\n",
        "print(\"torch cuda is available :\", torch.cuda.is_available())\n",
        "print(\"detectron2 version      :\", detectron2.__version__)"
      ],
      "metadata": {
        "id": "ZvGAEKxTm8CD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import some common libraries\n",
        "import numpy as np\n",
        "import os, cv2\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "# import some common detectron2 utilities\n",
        "from detectron2 import model_zoo\n",
        "from detectron2.engine import DefaultPredictor\n",
        "from detectron2.config import get_cfg\n",
        "from detectron2.utils.visualizer import Visualizer\n",
        "from detectron2.data import MetadataCatalog, DatasetCatalog"
      ],
      "metadata": {
        "id": "1G3bqpKhrVGv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. COCOデータセットの画像を用いた推論（物体検出）\n",
        "\n"
      ],
      "metadata": {
        "id": "LZL9SU-iMfnX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## COCOデータセットの読み込み\n",
        "COCOデータセットから画像をダウンロードします．\n",
        "まずは，画像を表示してみましょう．"
      ],
      "metadata": {
        "id": "Yczqvo93f11E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget http://images.cocodataset.org/val2017/000000439715.jpg -q -O coco_input.jpg\n",
        "img = cv2.imread(\"./coco_input.jpg\")\n",
        "cv2_imshow(img)"
      ],
      "metadata": {
        "id": "5C0inoy1rlLl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 推論用のconfigを設定\n",
        "Detectron2にはデフォルトの設定があるので，変更が必要なところだけ変更をします．\n",
        "\n",
        "ここで事前学習済みファイルを読み込むことで，事前学習済みモデルを使用することができます．"
      ],
      "metadata": {
        "id": "2iOi7e3JOl6w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Detectron2のデフォルトの設定ファイルをコピー\n",
        "cfg = get_cfg()\n",
        "# Faster R-CNNの事前学習済みモデル(のチェックポイント)と，モデル固有の設定ファイルを読み込み\n",
        "cfg.merge_from_file(model_zoo.get_config_file(\"COCO-Detection/faster_rcnn_R_50_FPN_3x.yaml\"))\n",
        "cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\"COCO-Detection/faster_rcnn_R_50_FPN_3x.yaml\")\n",
        "# 出力するbounding boxのスコアの閾値を設定\n",
        "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.7"
      ],
      "metadata": {
        "id": "mhVPyZxlD0js"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 推論の実行\n",
        "Detectron2には推論のためのシンプルなクラス (`DefaultPredictor`) が用意されています．それを使用することで簡単に推論が可能です．"
      ],
      "metadata": {
        "id": "PTJdeOaoTtJa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "predictor = DefaultPredictor(cfg)\n",
        "outputs = predictor(img)"
      ],
      "metadata": {
        "id": "oxLb6-8dTs0A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 推論結果の確認\n",
        "推論結果が格納されている`outputs`の中身を確認していきましょう．\n",
        "以下のリンク先のドキュメントには，`outputs`の形式が示されています．細かい形式を確認したい人は[公式ドキュメント](https://detectron2.readthedocs.io/en/latest/tutorials/models.html#model-output-format)を確認してみてください．"
      ],
      "metadata": {
        "id": "JcOc1LasZC5p"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**outputsの型とkeyを確認**\n",
        "\n",
        "`outputs`は辞書型となっています．今回のFaster R-CNNの推論結果では`instances`のkeyのみ入ってることが確認できます．"
      ],
      "metadata": {
        "id": "YrJZahu3hBPV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(type(outputs))\n",
        "print(outputs.keys())"
      ],
      "metadata": {
        "id": "WxJ3SznnhAF0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**インスタンスの中身を確認**\n",
        "\n",
        "`outputs[\"instances\"]`の中身を確認してみます．\n",
        "Instancesというクラスになっており，fieldsのところに\n",
        "\n",
        "*   pred_boxes: 推論したbounding box\n",
        "*   scores: 推論したbounding boxのスコア\n",
        "*   pred_classes: 推論したbounding boxのクラス\n",
        "\n",
        "が入っていることが確認できます．\n",
        "(参考: \n",
        " [Instancesクラスのドキュメント](https://detectron2.readthedocs.io/en/latest/modules/structures.html#detectron2.structures.Instances))\n"
      ],
      "metadata": {
        "id": "vydrrKMahbPk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "instances = outputs[\"instances\"]\n",
        "instances"
      ],
      "metadata": {
        "id": "bQOX7g8hYp9S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 推論結果の可視化\n",
        "Detectron2では，`Visualizer`クラスを用いて推論結果の可視化を簡単に行うことができます．"
      ],
      "metadata": {
        "id": "_9jGqtZ4TupQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "metadata = MetadataCatalog.get(cfg.DATASETS.TRAIN[0])\n",
        "vis = Visualizer(img[:,:,::-1], metadata)\n",
        "out = vis.draw_instance_predictions(instances.to(\"cpu\"))\n",
        "cv2_imshow(out.get_image()[:, :, ::-1])"
      ],
      "metadata": {
        "id": "ePoedEylTsAS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**メタデータの確認**\n",
        "\n",
        "上記コードに登場する`metadata`には，クラスラベルや色など，データセットのメタデータが入っています．このメタデータを用いて，`Visualizer`クラスのメソッドは推論結果の可視化を行っています．\n",
        "\n"
      ],
      "metadata": {
        "id": "TepYa6jkjNS1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 今回の可視化に用いるメタデータを確認\n",
        "metadata"
      ],
      "metadata": {
        "id": "m-Q8yZKHawxH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "また，メタデータの`thing_classes`を見ると，先ほどの`outputs`の`pred_classes`のラベルと名前を対応させることができます．例えば，`pred_classes`が0のところは，personだったことが分かります．"
      ],
      "metadata": {
        "id": "oqNb_lOcqMGP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ラベルが0のクラス名を確認\n",
        "metadata.get(\"thing_classes\")[0]"
      ],
      "metadata": {
        "id": "JJA1VgdUqKJg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## プチ演習: 推論結果のうち，馬のみを可視化してみよう\n",
        " [Instancesクラスのドキュメント](https://detectron2.readthedocs.io/en/latest/modules/structures.html#detectron2.structures.Instances)に書いてある通り，`Instances`クラスは条件を満たす部分インスタンスを抽出することができます．以下の例を参考にして，馬のインスタンスのみを抽出してみましょう．\n",
        "\n",
        "\n",
        "```\n",
        "例: \n",
        "category_3_detections = instances[instances.pred_classes == 3]\n",
        "confident_detections = instances[instances.scores > 0.9]\n",
        "```"
      ],
      "metadata": {
        "id": "IHKbiaxJouhY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "以下のコードを変更して，馬の検出結果のみを可視化してみましょう"
      ],
      "metadata": {
        "id": "X8tUzPn-uxQj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "###  ここから変更  ###\n",
        "horse_detections = instances\n",
        "### ここまでを変更 ###\n",
        "\n",
        "vis = Visualizer(img[:,:,::-1],MetadataCatalog.get(cfg.DATASETS.TRAIN[0]))\n",
        "out = vis.draw_instance_predictions(horse_detections.to(\"cpu\"))\n",
        "cv2_imshow(out.get_image()[:, :, ::-1])"
      ],
      "metadata": {
        "id": "XUEo6FhXuji0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**正解 (❗答え合わせのときに表示してください❗)**\n"
      ],
      "metadata": {
        "id": "W5tNK4JEu098"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title\n",
        "###  ここから変更  ###\n",
        "horse_detections = instances[instances.pred_classes == 17]\n",
        "### ここまでを変更 ###\n",
        "\n",
        "vis = Visualizer(img[:,:,::-1],MetadataCatalog.get(cfg.DATASETS.TRAIN[0]))\n",
        "out = vis.draw_instance_predictions(horse_detections.to(\"cpu\"))\n",
        "cv2_imshow(out.get_image()[:, :, ::-1])"
      ],
      "metadata": {
        "cellView": "form",
        "id": "QJvsa9NlsLrO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. COCOデータセットの画像を用いた推論（関連タスク）\n",
        "\n",
        "Detectron2を用いて，物体検出 (Object Detection)の推論を試すことができたので，次は\n",
        "*   Instance Segmentation\n",
        "*   Keypoint Detection\n",
        "*   Panoptic Segmentation\n",
        "\n",
        "の推論を試します．"
      ],
      "metadata": {
        "id": "aR4Nv2tlbh7X"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Detectorクラスの作成\n",
        "\n",
        "物体検出を試して分かる通り，全てのタスクで，事前学習済みモデルを読み込むところ以外はほとんど同じ操作で推論できます．そのため，今後はDetectorクラスに操作をまとめて実行していきます．"
      ],
      "metadata": {
        "id": "IGqXPz3vLoMV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Detector:\n",
        "  def __init__(self, model_type, th=0.7):\n",
        "    self.cfg = get_cfg()\n",
        "    self.model_type = model_type\n",
        "\n",
        "    if model_type == \"OD\": # object detection\n",
        "      model_path = \"COCO-Detection/faster_rcnn_R_50_FPN_3x.yaml\"\n",
        "    elif model_type == \"IS\": # instance segmentation\n",
        "      model_path = \"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\"\n",
        "    elif model_type == \"KP\": # keypoint detection\n",
        "      model_path = \"COCO-Keypoints/keypoint_rcnn_R_50_FPN_3x.yaml\"\n",
        "    elif model_type == \"PS\": # panoptic segmentation\n",
        "      model_path = \"COCO-PanopticSegmentation/panoptic_fpn_R_101_3x.yaml\"\n",
        "    else:\n",
        "      raise NotImplementedError()\n",
        "    \n",
        "    # load model config and pretrained model\n",
        "    self.cfg.merge_from_file(model_zoo.get_config_file(model_path))\n",
        "    self.cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(model_path)\n",
        "    # set threshold for this model\n",
        "    self.cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = th  \n",
        "    # cpu or cuda\n",
        "    self.cfg.MODEL.DEVICE = \"cuda\" \n",
        "    \n",
        "    self.predictor = DefaultPredictor(self.cfg)\n",
        "  \n",
        "  def _draw_predictions(self, img):\n",
        "    viz = Visualizer(img[:,:,::-1], metadata=MetadataCatalog.get(self.cfg.DATASETS.TRAIN[0]))\n",
        "    if self.model_type == \"PS\":\n",
        "      predictions, segments_info = self.predictor(img)[\"panoptic_seg\"]\n",
        "      out = viz.draw_panoptic_seg_predictions(predictions.to(\"cpu\"), segments_info)\n",
        "    else:\n",
        "      predictions = self.predictor(img)\n",
        "      out = viz.draw_instance_predictions(predictions[\"instances\"].to(\"cpu\"))\n",
        "    return out\n",
        "\n",
        "  def on_image(self, src_path, dst_width=640):\n",
        "    img = cv2.imread(src_path)\n",
        "\n",
        "    # resize if img is too large\n",
        "    h, w = img.shape[:2]\n",
        "    if w > dst_width:\n",
        "      dst_height = round(h * (dst_width / w))\n",
        "      img = cv2.resize(img, dsize=(dst_width, dst_height))\n",
        "    \n",
        "    out = self._draw_predictions(img)    \n",
        "    cv2_imshow(out.get_image()[:, :, ::-1])\n",
        "  \n",
        "  def on_video(self, src_path, dst_path='./video_out.mp4', dst_width=640):\n",
        "    cap = cv2.VideoCapture(src_path)\n",
        "    w = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "    h = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "    fps = float(cap.get(cv2.CAP_PROP_FPS))\n",
        "\n",
        "    if w > dst_width:\n",
        "      dst_height = round(h * (dst_width / w))\n",
        "    else:\n",
        "      dst_height = h\n",
        "    fourcc = cv2.VideoWriter_fourcc('m', 'p', '4', 'v')\n",
        "    rec = cv2.VideoWriter(dst_path, fourcc, fps, (dst_width, dst_height))\n",
        "\n",
        "    if not cap.isOpened():\n",
        "      print(\"Error opening the video...\")\n",
        "      return\n",
        "    \n",
        "    while True:\n",
        "      ret, frame = cap.read()\n",
        "      if not ret:\n",
        "        break\n",
        "      \n",
        "      resized_frame = cv2.resize(frame, dsize=(dst_width, dst_height))\n",
        "      out = self._draw_predictions(resized_frame)\n",
        "\n",
        "      rec.write(out.get_image()[:, :, ::-1])\n",
        "    \n",
        "    rec.release()"
      ],
      "metadata": {
        "id": "uLhmOooJMEI0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Object Detection\n",
        "\n",
        "先ほど試した物体検出の推論は，Detectorクラスを用いて以下のように書くことができるようになりました．"
      ],
      "metadata": {
        "id": "ICzFu2qe0rt8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "coco_img_path = \"./coco_input.jpg\"\n",
        "detector = Detector(\"OD\")\n",
        "detector.on_image(coco_img_path)"
      ],
      "metadata": {
        "id": "JdYpdtpYvujM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Instance Segmentation"
      ],
      "metadata": {
        "id": "3Z5o7O2lvvCF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "detector = Detector(\"IS\")\n",
        "detector.on_image(coco_img_path)"
      ],
      "metadata": {
        "id": "O4-g7Ix8r3Ro"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Keypoint Detection"
      ],
      "metadata": {
        "id": "v2Kg8GyWZxzV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "detector = Detector(\"KP\")\n",
        "detector.on_image(coco_img_path)"
      ],
      "metadata": {
        "id": "4AvKzswMadr6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Panoptic Segmentation"
      ],
      "metadata": {
        "id": "A13E1TJ4sTun"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "detector = Detector(\"PS\")\n",
        "detector.on_image(coco_img_path)"
      ],
      "metadata": {
        "id": "8_XUnm2maqGz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4. Google Drive内の画像を用いた推論\n",
        "\n",
        "各自用意してもらった画像で，物体検出や関連タスクの推論をしてもらいます！\n",
        "\n",
        "Google Driveのマイドライブ内に，推論を試してみたい画像を保存してください．\n",
        "（マイドライブ直下だと操作が簡単です．）"
      ],
      "metadata": {
        "id": "WZwClE_1tm7Y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ドライブをマウント\n",
        "\n",
        "Google Drive内のファイルにアクセスするには，マウントが必要です．\n",
        "\n",
        "以下のセルを実行後，ポップアップが表示されます．「Googleドライブに接続」をクリックして，ドライブを接続するアカウントを選択し，接続を許可してください．\n",
        "\n",
        "`Mounted at /content/drive`と表示されれば成功です."
      ],
      "metadata": {
        "id": "ZP6OKxpq7SRG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "-i6K-0altjQp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 推論に用いる画像の準備\n",
        "\n",
        "`img_path_from_drive`に，マイドライブからの画像のパスを代入してください．\n",
        "マイドライブ直下の場合は，画像のファイル名でOKです．"
      ],
      "metadata": {
        "id": "FyW3LNYj8x2M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# マイドライブからの画像のパスを代入\n",
        "img_path_from_drive = \"drive_input.jpg\""
      ],
      "metadata": {
        "id": "NbuA1B585NvD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# このセルは変更しない\n",
        "drive_path = \"drive/MyDrive\"\n",
        "drive_img_path = os.path.join(drive_path, img_path_from_drive)"
      ],
      "metadata": {
        "id": "cJFjD_Je4ur-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**推論に用いる画像を表示**\n",
        "\n",
        "ドライブのマウントと画像のパスの設定が正しくできていれば，推論に用いる画像が表示されます．"
      ],
      "metadata": {
        "id": "6YfDhEiaAoUb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "img = cv2.imread(drive_img_path)\n",
        "\n",
        "# resize if img is too large\n",
        "dst_width = 640\n",
        "h, w = img.shape[:2]\n",
        "if w > dst_width:\n",
        "  dst_height = round(h * (dst_width / w))\n",
        "  img = cv2.resize(img, dsize=(dst_width, dst_height))\n",
        "\n",
        "cv2_imshow(img)"
      ],
      "metadata": {
        "id": "axtLTu2M51te"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 推論の実行"
      ],
      "metadata": {
        "id": "nkZ03yLW9uSb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Object Detection\n",
        "detector = Detector(\"OD\")\n",
        "detector.on_image(drive_img_path)"
      ],
      "metadata": {
        "id": "e5L5l41p3-ho"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Instance Segmentation\n",
        "detector = Detector(\"IS\")\n",
        "detector.on_image(drive_img_path)"
      ],
      "metadata": {
        "id": "11faReOp4VK-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Keypoint Detection\n",
        "detector = Detector(\"KP\")\n",
        "detector.on_image(drive_img_path)"
      ],
      "metadata": {
        "id": "b-M4TX_Z4YyH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Panoptic Segmentation\n",
        "detector = Detector(\"PS\")\n",
        "detector.on_image(drive_img_path)"
      ],
      "metadata": {
        "id": "7GuwN9DD4bY3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 5. 動画を用いた推論"
      ],
      "metadata": {
        "id": "m2vkriK9ZeKb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ドライブ内の動画を用いた推論"
      ],
      "metadata": {
        "id": "xEiEKklWBavY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### セットアップ"
      ],
      "metadata": {
        "id": "MSa3AanoGDAA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import HTML\n",
        "import base64\n",
        "import io\n",
        "\n",
        "# Google Colabolatoryで動画を再生するための関数\n",
        "def play(file_path):\n",
        "    video = io.open(file_path, 'r+b').read()\n",
        "    encoded = base64.b64encode(video)\n",
        "    return(HTML(data='''<video controls><source src=\"data:video/mp4;base64,{0}\" type=\"video/mp4\" /></video>'''.format(encoded.decode('ascii'))))"
      ],
      "metadata": {
        "id": "NBvgWyM5GBrS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 推論に用いる動画の準備\n",
        "\n",
        "`video_path_from_drive`に，マイドライブからの動画のパスを代入してください．\n",
        "マイドライブ直下の場合は，動画のファイル名でOKです．\n",
        "\n",
        "**❗注意❗**\n",
        "動画が長すぎると処理が重たくなってしまうため，動画の長さは**10秒以内**程度に収めてください．"
      ],
      "metadata": {
        "id": "X1OiiEMlDAeD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ドライブをマウント（マウントができていない場合）\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "IizZwOYZETLK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# マイドライブからの画像のパスを代入\n",
        "video_path_from_drive = \"drive_input.mp4\""
      ],
      "metadata": {
        "id": "RQmecJQRDQSA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# このセルは変更しない\n",
        "drive_path = \"drive/MyDrive\"\n",
        "drive_video_path = os.path.join(drive_path, video_path_from_drive)"
      ],
      "metadata": {
        "id": "B_i8xXiiDZlJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 推論の実行\n",
        "以下の例では，Panoptic Segmentationの例を載せています．\n",
        "`Detector`の引数を変えて，試してみたいタスクを実行してみてください．"
      ],
      "metadata": {
        "id": "YX4vR71QDx7B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Panoptic Segmentation\n",
        "detector = Detector(\"PS\")"
      ],
      "metadata": {
        "id": "l40-RyZtDiTp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# このセルは変更しない\n",
        "dst_path = \"./drive_out.mp4\"\n",
        "play_path = \"./out.webm\"\n",
        "\n",
        "detector.on_video(src_path=drive_video_path, dst_path=dst_path)\n",
        "!ffmpeg -i '{dst_path}' -vcodec vp9 '{play_path}'\n",
        "play(play_path)"
      ],
      "metadata": {
        "id": "m1904wuOFHDo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Youtubeの動画を用いた推論"
      ],
      "metadata": {
        "id": "lnuMMw0sZmZs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### セットアップ"
      ],
      "metadata": {
        "id": "dJw_E_aICb7A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Youtube動画をダウンロードするライブラリのインストール\n",
        "!pip install yt-dlp"
      ],
      "metadata": {
        "id": "PzVHae3Eup_P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import YouTubeVideo, display, HTML\n",
        "import base64\n",
        "import io\n",
        "\n",
        "# Google Colabolatoryで動画を再生するための関数\n",
        "def play(file_path):\n",
        "    video = io.open(file_path, 'r+b').read()\n",
        "    encoded = base64.b64encode(video)\n",
        "    return(HTML(data='''<video controls><source src=\"data:video/mp4;base64,{0}\" type=\"video/mp4\" /></video>'''.format(encoded.decode('ascii'))))"
      ],
      "metadata": {
        "id": "vc7jMurkGXQ1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 推論に用いる動画の準備\n",
        "\n",
        "推論に用いる**動画のIDを取得してください**．動画のIDはURLから分かります．\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "例1.   https://www.youtube.com/watch?v=ll8TgCZ0plk のようなアドレスの場合\n",
        "\n",
        "  → 動画IDは`?v=`の後の`ll8TgCZ0plk`です．もし`&`が出てくる場合は，`&`の手前までです．\n",
        "\n",
        "例2.   https://youtu.be/ll8TgCZ0plk のようなアドレスの場合\n",
        "\n",
        "  → 動画IDは`youtu.be/`の後の`ll8TgCZ0plk`です．\n",
        "\n",
        "---\n",
        "\n",
        "Youtubeを開いて動画下部の「共有」を押して表示されるURLは例2のパターンとなるので，分からない場合は**「共有」からリンクを取得するのが分かりやすいです**．\n"
      ],
      "metadata": {
        "id": "hBldd2RdCsjh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 推論に用いる動画のIDを代入\n",
        "youtube_video_id = \"ll8TgCZ0plk\""
      ],
      "metadata": {
        "id": "ULMUFtmmK-zd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**推論に用いる動画を表示**\n",
        "\n",
        "YoutubeのIDの設定が正しくできていれば，推論に用いる動画が表示されます．"
      ],
      "metadata": {
        "id": "1VmSHCIYK-Ko"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "video = YouTubeVideo(youtube_video_id, width=640)\n",
        "display(video)"
      ],
      "metadata": {
        "id": "e1L54_qx3t_K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**動画のダウンロード**"
      ],
      "metadata": {
        "id": "qNSO43g-QMLw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "youtube_video_link = f\"https://www.youtube.com/watch?v={youtube_video_id}\"\n",
        "!yt-dlp '{youtube_video_link}' -f 22 -o youtube_input.mp4"
      ],
      "metadata": {
        "id": "R-NWRjg13az6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**動画の切り出し**\n",
        "\n",
        "Youtubeの動画をそのまま使うと長くなってしまうので，短い時間に切り出します．下のセルでは，最初から10秒間を切り出します．\n",
        "\n",
        "もし切り出しの開始時間を指定したい場合は，下記の例のように，`-ss`オプションを追加してください．ただし，`-ss`の値通りに切り出されない (不正確な) 可能性があります． (参考: [FFmpegのwiki](https://trac.ffmpeg.org/wiki/Seeking))\n",
        "\n",
        "\n",
        "```\n",
        "# 5分地点から10秒間の動画を切り出す例\n",
        "!ffmpeg -ss 300 -i youtube_input.mp4 -t 10 -c:v copy youtube_input_clip.mp4\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "Bp3eT_2oPu6S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!ffmpeg -i youtube_input.mp4 -t 10 -c:v copy youtube_input_clip.mp4"
      ],
      "metadata": {
        "id": "PNyKuBdd3kdF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 推論の実行\n",
        "以下の例では，Panoptic Segmentationの例を載せています．\n",
        "`Detector`の引数を変えて，試してみたいタスクを実行してみてください．"
      ],
      "metadata": {
        "id": "hK1Rv0JpKnRc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Panoptic Segmentation\n",
        "detector = Detector(\"PS\")"
      ],
      "metadata": {
        "id": "4UEcy9iXtMRY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# このセルは変更しない\n",
        "src_path = \"./youtube_input_clip.mp4\"\n",
        "dst_path = \"./youtube_out.mp4\"\n",
        "play_path = \"./out.webm\"\n",
        "\n",
        "detector.on_video(src_path=src_path, dst_path=dst_path)\n",
        "!ffmpeg -i '{dst_path}' -vcodec vp9 '{play_path}'\n",
        "play(play_path)"
      ],
      "metadata": {
        "id": "h8VFenz-d6U6"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}